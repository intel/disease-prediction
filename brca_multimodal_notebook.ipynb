{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9ea5f1f-3f56-4d50-af00-df54361a5196",
   "metadata": {},
   "source": [
    "# Multi-Modal Disease Prediction\n",
    "Many reference kits  in the bio-medical domain focus on a single-model and single-modal solution. Exclusive reliance on a single method has some limitations, such as impairing the design of robust and accurate classifiers for complex datasets. To overcome these limitations, we provide this multi-modal disease prediction reference kit.\n",
    "\n",
    "Multi-modal disease prediction is an Intel  optimized, end-to-end reference kit for fine-tuning and inference. This reference kit implements a multi-model and multi-modal solution that will help to predict diagnosis by using categorized contrast enhanced mammography data and radiologists’ notes.\n",
    " \n",
    "\n",
    "## **Table of Contents**\n",
    "- [Overview](#overview)\n",
    "- [Validated Hardware Details](#validated-hardware-details)\n",
    "- [Software Requirements](#software-requirements)\n",
    "- [How it Works?](#how-it-works)\n",
    "    - [Architecture](#architecture)\n",
    "- [Get Started](#get-started)\n",
    "- [Run Using Jupyter Lab](#run-using-jupyter-lab) \n",
    "- [Expected Output](#expected-output)\n",
    "- [Result Visualization](#result-visualization)\n",
    "\n",
    "<a id=\"overview\"></a> \n",
    "## Overview\n",
    "This reference kit demonstrates one possible reference implementation of a multi-model and multi-modal solution. While the vision workflow aims to train an image classifier that takes in contrast-enhanced spectral mammography (CESM) images, the natural language processing (NLP) workflow aims to train a document classifier that takes in annotation notes about a patient’s symptoms. Each pipeline creates prediction for the diagnosis of breast cancer. In the end, weighted ensemble method is used to create final prediction.\n",
    "\n",
    "The goal is to minimize an expert’s involvement in categorizing samples as normal, benign, or malignant, by developing and optimizing a decision support system that automatically categorizes the CESM with the help of radiologist notes.\n",
    "\n",
    "<a id=\"validated-hardware-details\"></a> \n",
    "## Validated Hardware Details\n",
    "There are workflow-specific hardware and software setup requirements depending on how the workflow is run. Bare metal development system and Docker image running locally have the same system requirements. \n",
    "\n",
    "| Recommended Hardware         | Precision  |\n",
    "| ---------------------------- | ---------- |\n",
    "| Intel® 4th Gen Xeon® Scalable Performance processors| FP32, BF16 |\n",
    "| Intel® 1st, 2nd, 3rd, and 4th Gen Xeon® Scalable Performance processors| FP32 |\n",
    "\n",
    "To execute the reference solution presented here, please use CPU for fine tuning. \n",
    "\n",
    "<a id=\"software-requirements\"></a> \n",
    "## Software Requirements \n",
    "Linux OS (Ubuntu 22.04) is used in this reference solution. Make sure the following dependencies are installed.\n",
    "\n",
    "1. `sudo apt update`\n",
    "2. `sudo apt install -y build-essential gcc git libgl1-mesa-glx libglib2.0-0 python3-dev`\n",
    "3. Python3.9, Pip/Conda and python3.9-venv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ec95594-e5bf-4e07-83bd-213f681d0fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sudo] password for aagalleg: [sudo] password for aagalleg: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...Get:1 https://download.docker.com/linux/ubuntu focal InRelease [57.7 kB]\n",
      "Get:2 https://cli.github.com/packages stable InRelease [3917 B]\n",
      "Get:3 https://download.docker.com/linux/ubuntu focal/stable amd64 Packages [29.7 kB]\n",
      "Hit:4 http://ubuntu.osuosl.org/ubuntu focal InRelease\n",
      "Get:5 http://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]\n",
      "\n",
      "Reading state information...\n",
      "Get:6 https://cli.github.com/packages stable/main amd64 Packages [346 B]\n",
      "Get:7 http://ubuntu.osuosl.org/ubuntu focal-updates InRelease [114 kB]\n",
      "Err:5 http://packages.cloud.google.com/apt cloud-sdk InRelease\n",
      "  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05\n",
      "gcc is already the newest version (4:9.3.0-1ubuntu2).\n",
      "gcc set to manually installed.\n",
      "python3-dev is already the newest version (3.8.2-0ubuntu2).\n",
      "build-essential is already the newest version (12.8ubuntu1.1).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  libpython2-dev libpython2-stdlib libpython2.7 libpython2.7-dev\n",
      "  libpython2.7-minimal libpython2.7-stdlib python2-minimal python2.7-minimal\n",
      "  python3-backcall python3-ipython python3-jedi python3-parso\n",
      "  python3-pickleshare python3-prompt-toolkit\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "The following additional packages will be installed:\n",
      "  libglib2.0-bin\n",
      "Suggested packages:\n",
      "  git-daemon-run | git-daemon-sysvinit git-doc git-el git-email git-gui gitk\n",
      "  gitweb git-cvs git-mediawiki git-svn\n",
      "The following NEW packages will be installed:\n",
      "  libgl1-mesa-glx\n",
      "The following packages will be upgraded:\n",
      "  git libglib2.0-0 libglib2.0-bin\n",
      "Get:8 http://ubuntu.osuosl.org/ubuntu focal-security InRelease [114 kB]\n",
      "3 upgraded, 1 newly installed, 0 to remove and 470 not upgraded.\n",
      "Need to get 4534 kB/5899 kB of archives.\n",
      "After this operation, 119 kB of additional disk space will be used.\n",
      "Ign:1 http://ubuntu.osuosl.org/ubuntu focal-updates/main amd64 git amd64 1:2.25.1-1ubuntu3.10\n",
      "Get:9 http://ubuntu.osuosl.org/ubuntu focal-backports InRelease [108 kB]\n",
      "Err:1 http://ubuntu.osuosl.org/ubuntu focal-updates/main amd64 git amd64 1:2.25.1-1ubuntu3.10\n",
      "  404  Not Found [IP: 10.7.211.16 911]\n",
      "Get:10 http://ubuntu.osuosl.org/ubuntu focal-updates/main amd64 Packages [2571 kB]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E: Failed to fetch http://ubuntu.osuosl.org/ubuntu/pool/main/g/git/git_2.25.1-1ubuntu3.10_amd64.deb  404  Not Found [IP: 10.7.211.16 911]\n",
      "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:11 http://ubuntu.osuosl.org/ubuntu focal-updates/main Translation-en [434 kB]\n",
      "Get:12 http://ubuntu.osuosl.org/ubuntu focal-updates/main amd64 c-n-f Metadata [16.6 kB]\n",
      "Get:13 http://ubuntu.osuosl.org/ubuntu focal-updates/universe amd64 Packages [1063 kB]\n",
      "Get:14 http://ubuntu.osuosl.org/ubuntu focal-updates/universe Translation-en [252 kB]\n",
      "Get:15 http://ubuntu.osuosl.org/ubuntu focal-updates/universe amd64 c-n-f Metadata [24.3 kB]\n",
      "Get:16 http://ubuntu.osuosl.org/ubuntu focal-updates/multiverse amd64 Packages [25.2 kB]\n",
      "Get:17 http://ubuntu.osuosl.org/ubuntu focal-updates/restricted amd64 Packages [1879 kB]\n",
      "Get:18 http://ubuntu.osuosl.org/ubuntu focal-updates/restricted Translation-en [264 kB]\n",
      "Get:19 http://ubuntu.osuosl.org/ubuntu focal-security/main amd64 Packages [2191 kB]\n",
      "Get:20 http://ubuntu.osuosl.org/ubuntu focal-security/main Translation-en [353 kB]\n",
      "Get:21 http://ubuntu.osuosl.org/ubuntu focal-security/main amd64 c-n-f Metadata [13.0 kB]\n",
      "Get:22 http://ubuntu.osuosl.org/ubuntu focal-security/universe amd64 Packages [838 kB]\n",
      "Get:23 http://ubuntu.osuosl.org/ubuntu focal-security/universe Translation-en [172 kB]\n",
      "Get:24 http://ubuntu.osuosl.org/ubuntu focal-security/universe amd64 c-n-f Metadata [17.7 kB]\n",
      "Get:25 http://ubuntu.osuosl.org/ubuntu focal-security/restricted amd64 Packages [1770 kB]\n",
      "Get:26 http://ubuntu.osuosl.org/ubuntu focal-security/restricted Translation-en [249 kB]\n",
      "Get:27 http://ubuntu.osuosl.org/ubuntu focal-backports/main amd64 Packages [45.7 kB]\n",
      "Get:28 http://ubuntu.osuosl.org/ubuntu focal-backports/main amd64 c-n-f Metadata [1420 B]\n",
      "Get:29 http://ubuntu.osuosl.org/ubuntu focal-backports/universe amd64 Packages [25.0 kB]\n",
      "Get:30 http://ubuntu.osuosl.org/ubuntu focal-backports/universe amd64 c-n-f Metadata [880 B]\n",
      "Reading package lists...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: GPG error: http://packages.cloud.google.com/apt cloud-sdk InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05\n",
      "E: The repository 'http://packages.cloud.google.com/apt cloud-sdk InRelease' is not signed.\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "password = getpass.getpass()\n",
    "command = 'sudo -S apt-get update'\n",
    "os.popen(command, 'w').write(password+'\\n')\n",
    "command = 'sudo -S apt-get install -y build-essential gcc git libgl1-mesa-glx libglib2.0-0 python3-dev'\n",
    "os.popen(command, 'w').write(password+'\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e233e40-cb7f-4200-997c-ef659f679972",
   "metadata": {},
   "source": [
    "<a id=\"how-it-works\"></a> \n",
    "## How It Works?\n",
    "\n",
    "<a id=\"architecture\"></a> \n",
    "### Architecture\n",
    "![Use_case_flow](assets/e2e_flow_HLS_Disease_Prediction.png)\n",
    "*Figure-1: Architecture of the reference kit* \n",
    "\n",
    "- Uses real-world CESM breast cancer datasets with “multi-modal and multi-model” approaches.\n",
    "- Two domain toolkits (Intel® Transfer Learning Toolkit and Intel® Extension for Transformers), Intel® Neural Compressor and other libs/tools and uses Hugging Face model repo and APIs for [ResNet-50](https://huggingface.co/microsoft/resnet-50) and [ClinicalBert](https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT) models. \n",
    "- The NLP reference Implementation component uses [HF Fine-tuning and Inference Optimization workload](https://github.com/intel/intel-extension-for-transformers/tree/main/workflows/hf_finetuning_and_inference_nlp), which is optimized for document classification. This NLP workload employs Intel® Neural Compressor and other libraries/tools and utilizes Hugging Face model repository and APIs for ClinicalBert models. The ClinicalBert model, which is pretrained with a Masked-Language-Modeling task on a large corpus of English language from MIMIC-III data, is fine-tuned with the CESM breast cancer annotation dataset to generate a new BERT model.\n",
    "- The Vision reference Implementation component uses [TLT-based vision workload](https://github.com/IntelAI/transfer-learning), which is optimized for image fine-tuning and inference. This workload utilizes Intel® Transfer Learning Tool and tfhub's ResNet-50 model to fine-tune a new convolutional neural network model with subtracted CESM image dataset. The images are preprocessed by using domain expert-defined segmented regions to reduce redundancies during training.\n",
    "- Predict diagnosis by using categorized contrast enhanced mammography images and radiologists’ notes separately and weighted ensemble method applied to results of sub-models to create the final prediction.\n",
    "\n",
    "<a id=\"get-started\"></a> \n",
    "## Get Started\n",
    "\n",
    "### Download the Reference Kit Repository\n",
    "If previously not done, from terminal create a working directory for the reference kit and clone the [Breast Cancer Prediction Reference Kit](https://github.com/intel/disease-prediction) repository into your working directory.\n",
    "```\n",
    "git clone https://github.com/intel/disease-prediction.git brca_multimodal\n",
    "cd brca_multimodal\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d9a697e-db85-4995-8c45-52dd94d9ce46",
   "metadata": {},
   "source": [
    "### DataSet\n",
    "The dataset is a collection of 2,006 high-resolution contrast-enhanced spectral mammography (CESM) images (1003 low energy images and 1003 subtracted CESM images) with annotations of 326 female patients. See Figure-1. Each patient has 8 images, 4 representing each side with two views (Top Down looking and Angled Top View) consisting of low energy and subtracted CESM images. Medical reports, written by radiologists, are provided for each case along with manual segmentation annotation for the abnormal findings in each image. As a preprocessing step, we segment the images based on the manual segmentation to get the region of interest and group annotation notes based on the subject and breast side. \n",
    "\n",
    "  ![CESM Images](assets/cesm_and_annotation.png)\n",
    "\n",
    "*Figure-2: Samples of low energy and subtracted CESM images and Medical reports, written by radiologists from the Categorized contrast enhanced mammography dataset. [(Khaled, 2022)](https://www.nature.com/articles/s41597-022-01238-0)*\n",
    "\n",
    "For more details of the dataset, visit the wikipage of the [CESM](https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=109379611#109379611bcab02c187174a288dbcbf95d26179e8) and read [Categorized contrast enhanced mammography dataset for diagnostic and artificial intelligence research](https://www.nature.com/articles/s41597-022-01238-0).\n",
    "\n",
    "#### Setting Up the Data\n",
    "Use the links below to download the image datasets.\n",
    "\n",
    "- [High-resolution Contrast-enhanced spectral mammography (CESM) images](https://faspex.cancerimagingarchive.net/aspera/faspex/external_deliveries/260?passcode=5335d2514638afdaf03237780dcdfec29edf4238#)\n",
    "\n",
    "Copy all the downloaded files into the *data* directory.\n",
    "\n",
    "**Note:** See this dataset's applicable license for terms and conditions. Intel Corporation does not own the rights to this dataset and does not confer any rights to it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "859bce34-5cf5-4df7-8b66-48dc56b47473",
   "metadata": {},
   "source": [
    "<a id=\"run-using-jupyter-lab\"></a> \n",
    "# Run Using Jupyter Lab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab0e33d4-8990-446b-8617-61049d5a9003",
   "metadata": {},
   "source": [
    "### 1. Create Conda Environment \n",
    "\n",
    "If not previously created, users are encouraged to use python virtual environments for consistent package management\n",
    "\n",
    "Using virtualenv:\n",
    "\n",
    "```\n",
    "python3.9 -m venv hls_env\n",
    "source hls_env/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb4d5ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in ./hls_env/lib/python3.9/site-packages (6.23.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./hls_env/lib/python3.9/site-packages (from ipykernel) (8.2.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./hls_env/lib/python3.9/site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in ./hls_env/lib/python3.9/site-packages (from ipykernel) (1.5.6)\n",
      "Requirement already satisfied: tornado>=6.1 in ./hls_env/lib/python3.9/site-packages (from ipykernel) (6.3.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./hls_env/lib/python3.9/site-packages (from ipykernel) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./hls_env/lib/python3.9/site-packages (from ipykernel) (1.6.7)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./hls_env/lib/python3.9/site-packages (from ipykernel) (5.9.0)\n",
      "Requirement already satisfied: psutil in ./hls_env/lib/python3.9/site-packages (from ipykernel) (5.9.5)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./hls_env/lib/python3.9/site-packages (from ipykernel) (5.3.0)\n",
      "Requirement already satisfied: pyzmq>=20 in ./hls_env/lib/python3.9/site-packages (from ipykernel) (25.0.2)\n",
      "Requirement already satisfied: packaging in ./hls_env/lib/python3.9/site-packages (from ipykernel) (23.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./hls_env/lib/python3.9/site-packages (from ipykernel) (8.13.2)\n",
      "Requirement already satisfied: typing-extensions in ./hls_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.5.0)\n",
      "Requirement already satisfied: backcall in ./hls_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in ./hls_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.18.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./hls_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (2.15.1)\n",
      "Requirement already satisfied: decorator in ./hls_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in ./hls_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in ./hls_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./hls_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (3.0.38)\n",
      "Requirement already satisfied: stack-data in ./hls_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.6.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in ./hls_env/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (6.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./hls_env/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./hls_env/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./hls_env/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.15.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./hls_env/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./hls_env/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./hls_env/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel) (0.2.6)\n",
      "Requirement already satisfied: six>=1.5 in ./hls_env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./hls_env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./hls_env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in ./hls_env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/localdisk/aagalleg/dp_demo/disease-prediction/hls_env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalled kernelspec hls_env in /ec/pdx/disks/mlp_lab_home_pool_02/aagalleg/.local/share/jupyter/kernels/hls_env\n"
     ]
    }
   ],
   "source": [
    "!python3.9 -m venv hls_env\n",
    "!hls_env/bin/python3 -m pip install ipykernel\n",
    "!hls_env/bin/python3 -m ipykernel install --user --name hls_env"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "978c9625",
   "metadata": {},
   "source": [
    "**NOTE:** Restart kernel and wait some seconds, and change kernel to hls_env. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097f09ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b445eb4",
   "metadata": {},
   "source": [
    "Or conda: If you don't already have conda installed, see the [Conda Linux installation instructions](https://docs.conda.io/projects/conda/en/stable/user-guide/install/linux.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e68bd-2dc4-40ce-856d-d821f366dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create --name hls_env python=3.9 ipykernel -y -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe3d63-5f51-4f1f-aabf-8c3e05abbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify hls_env environment is active\n",
    "!conda env list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6d53da4-e598-4850-bef2-59acd36022e4",
   "metadata": {},
   "source": [
    "**NOTE:** Restart kernel and wait some seconds, and change kernel to conda env:hls_env. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f59e7e-233f-4fab-ba31-4f140ba30a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8e5c0fc-f0eb-4a16-ba25-c500ecef10c8",
   "metadata": {},
   "source": [
    "### 2. Install Required Workflows and Preprocess the Data\n",
    "\n",
    "> Make sure [High-resolution Contrast-enhanced spectral mammography (CESM) images](https://faspex.cancerimagingarchive.net/aspera/faspex/external_deliveries/260?passcode=5335d2514638afdaf03237780dcdfec29edf4238#) are downloaded and copied into the *data* directory.\n",
    "\n",
    "This step involves the installation of the following components:\n",
    "\n",
    "- HF Fine-tune & Inference Optimization workflow\n",
    "- Transfer Learning based on TLT workflow\n",
    "- Model Zoo for Intel®\n",
    "\n",
    "Upon successful installation, the data is preprocessed.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf351f03-0f23-4033-9cd8-f3c1453ea9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "!bash setup_workflows.sh\n",
    "IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca24f317-c892-4db2-99a9-79fa5e9743d5",
   "metadata": {},
   "source": [
    "### 3. Model Building Process\n",
    "\n",
    "To train the multi-model disease prediction, utilize the 'breast_cancer_prediction.py' script along with the arguments outlined in the 'disease_prediction_baremetal.yaml' configuration file, which has the following structure:\n",
    "\n",
    "```\n",
    "disease_prediction_baremetal.yaml\n",
    "    \n",
    "    |\n",
    "    └──overwrite_training_testing_ids\n",
    "    └──output_dir\n",
    "    └──test_size\n",
    "    └──write\n",
    "    └──nlp\n",
    "        |── finetune\n",
    "        |── inference\n",
    "        └── other parameters for HF fine-tune and inference optimization workflow\n",
    "    └──vision\n",
    "        |── finetune\n",
    "        |── inference\n",
    "        └── other parameters for HF fine-tune and inference optimization workflow\n",
    "```\n",
    "\n",
    "The 'disease_prediction_baremetal.yaml' file includes the following parameters:\n",
    "\n",
    "- overwrite_training_testing_ids: uses previously created train and test data sets\n",
    "- output_dir: specifies the location of the output model and inference results\n",
    "- test_size: sets the percentage of the test data set\n",
    "- write: a container parameter that is set to false for bare metal\n",
    "- nlp:\n",
    "  - finetune: runs nlp fine-tuning\n",
    "  - inference: runs nlp inference\n",
    "  - additional parameters for the HF fine-tune and inference optimization workflow (more information available [here](https://github.com/intel/intel-extension-for-transformers/tree/main/workflows/hf_finetuning_and_inference_nlp/config))\n",
    "\n",
    "- vision:\n",
    "  - finetune: runs vision fine-tuning\n",
    "  - inference: runs vision inference\n",
    "  - additional parameters for the Vision: Transfer Learning Toolkit based on TLT workflow (more information available [here](https://github.com/IntelAI/transfer-learning/tree/f2e83f1614901d44d0fdd66f983de50551691676/workflows/disease_prediction))\n",
    "\n",
    "\n",
    "To solely perform the fine-tuning process, set the 'finetune' parameter to true in the 'disease_prediction.yaml' file and execute the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0aeb7f6-c6b0-44f2-b674-e4cd753183e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-24 14:23:31.977886: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Downloading and preparing dataset csv/default to /nfs/site/home/aagalleg/.cache/huggingface/datasets/csv/default-46482cb27128dd58/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n",
      "Downloading data files: 100%|███████████████████| 1/1 [00:00<00:00, 8240.28it/s]\n",
      "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1125.69it/s]\n",
      "Dataset csv downloaded and prepared to /nfs/site/home/aagalleg/.cache/huggingface/datasets/csv/default-46482cb27128dd58/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset csv/default to /nfs/site/home/aagalleg/.cache/huggingface/datasets/csv/default-038e6d293e01ec33/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n",
      "Downloading data files: 100%|███████████████████| 1/1 [00:00<00:00, 9020.01it/s]\n",
      "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1766.02it/s]\n",
      "Dataset csv downloaded and prepared to /nfs/site/home/aagalleg/.cache/huggingface/datasets/csv/default-038e6d293e01ec33/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at /nfs/site/home/aagalleg/.cache/huggingface/hub/models--emilyalsentzer--Bio_ClinicalBERT/snapshots/9b5e0380b37eac696b3ff68b5f319c554523971f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /nfs/site/home/aagalleg/.cache/huggingface/hub/models--emilyalsentzer--Bio_ClinicalBERT/snapshots/9b5e0380b37eac696b3ff68b5f319c554523971f/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /nfs/site/home/aagalleg/.cache/huggingface/hub/models--emilyalsentzer--Bio_ClinicalBERT/snapshots/9b5e0380b37eac696b3ff68b5f319c554523971f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /nfs/site/home/aagalleg/.cache/huggingface/hub/models--emilyalsentzer--Bio_ClinicalBERT/snapshots/9b5e0380b37eac696b3ff68b5f319c554523971f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /nfs/site/home/aagalleg/.cache/huggingface/hub/models--emilyalsentzer--Bio_ClinicalBERT/snapshots/9b5e0380b37eac696b3ff68b5f319c554523971f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /nfs/site/home/aagalleg/.cache/huggingface/hub/models--emilyalsentzer--Bio_ClinicalBERT/snapshots/9b5e0380b37eac696b3ff68b5f319c554523971f/pytorch_model.bin\n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/hls_env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "2023-05-24 14:23:41 [INFO] ***** Running training *****\n",
      "2023-05-24 14:23:41 [INFO]   Num examples = 507\n",
      "2023-05-24 14:23:41 [INFO]   Num Epochs = 8\n",
      "2023-05-24 14:23:41 [INFO]   Instantaneous batch size per device = 100\n",
      "2023-05-24 14:23:41 [INFO]   Total train batch size (w. parallel, distributed & accumulation) = 100\n",
      "2023-05-24 14:23:41 [INFO]   Gradient Accumulation steps = 1\n",
      "2023-05-24 14:23:41 [INFO]   Total optimization steps = 48\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|███████████████████████████████████████████| 48/48 [01:44<00:00,  1.78s/it]2023-05-24 14:25:25 [INFO] \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 104.0797, 'train_samples_per_second': 38.97, 'train_steps_per_second': 0.461, 'train_loss': 0.362823486328125, 'epoch': 8.0}\n",
      "100%|███████████████████████████████████████████| 48/48 [01:44<00:00,  2.17s/it]\n",
      "2023-05-24 14:25:25 [INFO] Saving model checkpoint to /localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/src/../output/nlp\n",
      "Configuration saved in /localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/src/../output/nlp/config.json\n",
      "Model weights saved in /localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/src/../output/nlp/pytorch_model.bin\n",
      "tokenizer config file saved in /localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/src/../output/nlp/tokenizer_config.json\n",
      "Special tokens file saved in /localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/src/../output/nlp/special_tokens_map.json\n",
      "***** Running Prediction *****\n",
      "  Num examples = 57\n",
      "  Batch size = 100\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 415.98it/s]\n",
      "\n",
      "*********** TEST_METRICS ***********\n",
      "Accuracy: 0.8596491228070176\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 507\n",
      "  Batch size = 100\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.67it/s]\n",
      "2023-05-24 14:25:30.567866: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Found cached dataset csv (/nfs/site/home/aagalleg/.cache/huggingface/datasets/csv/default-038e6d293e01ec33/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached processed dataset at /nfs/site/home/aagalleg/.cache/huggingface/datasets/csv/default-038e6d293e01ec33/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-12d694881c2ae4ca.arrow\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file /localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/src/../output/nlp/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/src/../output/nlp\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file /localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/src/../output/nlp/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/src/../output/nlp.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 57\n",
      "  Batch size = 100\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1157.05it/s]\n",
      "\n",
      "*********** TEST_METRICS ***********\n",
      "Accuracy: 0.8596491228070176\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 57\n",
      "  Batch size = 100\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1731.75it/s]\n",
      "['/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/vision_wf/workflows/disease_prediction/src/../../../', '/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/vision_wf/workflows/disease_prediction/src', '/localdisk/aagalleg/miniconda3/lib/python39.zip', '/localdisk/aagalleg/miniconda3/lib/python3.9', '/localdisk/aagalleg/miniconda3/lib/python3.9/lib-dynload', '/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/hls_env/lib/python3.9/site-packages']\n",
      "2023-05-24 14:25:39.720538: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "Model Loading time (s):  0.0036945343017578125\n",
      "Found 1433 files belonging to 3 classes.\n",
      "2023-05-24 14:25:41.353559: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 14:25:41.357691: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Class names: ['Benign', 'Malignant', 'Normal']\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:From /localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/hls_env/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Enabling auto_mixed_precision_mkl\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 2048)              23561152  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,185,667\n",
      "Trainable params: 2,624,515\n",
      "Non-trainable params: 23,561,152\n",
      "_________________________________________________________________\n",
      "Checkpoint directory: /localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/src/../output/vision/resnet_v1_50_checkpoints\n",
      "Epoch 1/5\n",
      "/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/hls_env/lib/python3.9/site-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2023-05-24 14:25:46.187311: W tensorflow/core/grappler/optimizers/meta_optimizer.cc:388] NOTE: auto_mixed_precision_mkl is deprecated. Please use auto_mixed_precision_onednn_bfloat16 instead\n",
      "2023-05-24 14:25:46.255887: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2254] Converted 204/1018 nodes to bfloat16 precision using 2 cast(s) to bfloat16 (excluding Const and Variable casts)\n",
      "     35/Unknown - 29s 724ms/step - loss: 0.7252 - acc: 0.71882023-05-24 14:26:13.034129: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "     36/Unknown - 30s 728ms/step - loss: 0.8312 - acc: 0.62502023-05-24 14:26:14.549028: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2254] Converted 195/809 nodes to bfloat16 precision using 1 cast(s) to bfloat16 (excluding Const and Variable casts)\n",
      "36/36 [==============================] - 37s 937ms/step - loss: 0.0000e+00 - acc: 0.0000e+00 - val_loss: 0.7185 - val_acc: 0.6868 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "36/36 [==============================] - 31s 865ms/step - loss: 0.7439 - acc: 0.6562 - val_loss: 0.6428 - val_acc: 0.7189 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "36/36 [==============================] - 30s 835ms/step - loss: 0.5750 - acc: 0.8125 - val_loss: 0.6273 - val_acc: 0.7402 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "36/36 [==============================] - 29s 795ms/step - loss: 0.4259 - acc: 0.8438 - val_loss: 0.6406 - val_acc: 0.7402 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "36/36 [==============================] - 28s 782ms/step - loss: 0.3558 - acc: 0.8438 - val_loss: 0.6664 - val_acc: 0.7224 - lr: 0.0010\n",
      "\n",
      "Total Vision Finetuning time (s):  156.50803971290588\n",
      "9/9 [==============================] - 5s 601ms/step - loss: 0.6664 - acc: 0.7224\n",
      "loss: 0.6664333343505859\n",
      "acc: 0.7224199175834656\n",
      "dict_metrics: {'e2e_training_time': 156.50803971290588, 'loss': 0.6664333343505859, 'acc': 0.7224199175834656}\n",
      "Finished Fine-tuning the vision model...\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "Saved model directory: /localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/src/../output/vision/resnet_v1_50/1\n",
      "Done finetuning the vision model ............\n",
      "Found 1433 files belonging to 3 classes.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 2048)              23561152  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,185,667\n",
      "Trainable params: 2,624,515\n",
      "Non-trainable params: 23,561,152\n",
      "_________________________________________________________________\n",
      "\n",
      " Vision Model Loading time:  4.283700942993164\n",
      "Found 1433 files belonging to 3 classes.\n",
      "/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/hls_env/lib/python3.9/site-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2023-05-24 14:28:33.580995: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2254] Converted 197/815 nodes to bfloat16 precision using 1 cast(s) to bfloat16 (excluding Const and Variable casts)\n",
      "45/45 [==============================] - 28s 614ms/step - loss: 0.6781 - acc: 0.7418\n",
      "loss: 0.6781412363052368\n",
      "acc: 0.7418004274368286\n",
      "Infering data in folder:  Malignant\n",
      "2023-05-24 14:29:01.989398: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2254] Converted 194/752 nodes to bfloat16 precision using 1 cast(s) to bfloat16 (excluding Const and Variable casts)\n",
      "Infering data in folder:  Benign\n",
      "Infering data in folder:  Normal\n",
      "Vision inference time:  140.95107889175415\n",
      "['/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/vision_wf/workflows/disease_prediction/src/../../../', '/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/vision_wf/workflows/disease_prediction/src', '/localdisk/aagalleg/miniconda3/lib/python39.zip', '/localdisk/aagalleg/miniconda3/lib/python3.9', '/localdisk/aagalleg/miniconda3/lib/python3.9/lib-dynload', '/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/hls_env/lib/python3.9/site-packages']\n",
      "2023-05-24 14:31:24.238376: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Found 1433 files belonging to 3 classes.\n",
      "2023-05-24 14:31:25.918624: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 14:31:25.922665: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 2048)              23561152  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,185,667\n",
      "Trainable params: 2,624,515\n",
      "Non-trainable params: 23,561,152\n",
      "_________________________________________________________________\n",
      "\n",
      " Vision Model Loading time:  4.170064210891724\n",
      "Found 146 files belonging to 3 classes.\n",
      "/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/hls_env/lib/python3.9/site-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "5/5 [==============================] - 3s 404ms/step - loss: 0.8436 - acc: 0.6507\n",
      "loss: 0.8435676097869873\n",
      "acc: 0.6506849527359009\n",
      "Infering data in folder:  Benign\n",
      "Infering data in folder:  Normal\n",
      "Infering data in folder:  Malignant\n",
      "Vision inference time:  11.265023469924927\n",
      "        Confusion Matrix for vision_predictions\n",
      "           Malignant  Normal  Benign  Recall\n",
      "Malignant     21.000   0.000   1.000   0.955\n",
      "Normal         1.000  10.000   9.000   0.500\n",
      "Benign         7.000   2.000   6.000   0.400\n",
      "Precision      0.724   0.833   0.375   0.649\n",
      "\n",
      "        Confusion Matrix for nlp_predictions\n",
      "           Malignant  Normal  Benign  Recall\n",
      "Malignant     19.000   0.000   3.000   0.864\n",
      "Normal         0.000  20.000   0.000   1.000\n",
      "Benign         4.000   1.000  10.000   0.667\n",
      "Precision      0.826   0.952   0.769   0.860\n",
      "\n",
      "        Confusion Matrix for ensemble_predictions\n",
      "           Malignant  Normal  Benign  Recall\n",
      "Malignant      20.00   0.000   2.000   0.909\n",
      "Normal          0.00  20.000   0.000   1.000\n",
      "Benign          3.00   1.000  11.000   0.733\n",
      "Precision       0.87   0.952   0.846   0.895\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!python src/breast_cancer_prediction.py --config_file configs/disease_prediction_baremetal.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d487fe-2931-45d8-8f07-a7cc20175a68",
   "metadata": {},
   "source": [
    "### 4. Running Inference\n",
    "After the models are trained and saved using the script from step 4, load the NLP and vision models using the inference option. This applies a weighted ensemble method to generate a final prediction. To only run inference, set the 'inference' parameter to true in the 'disease_prediction.yaml' file and run the command provided in step 4.\n",
    "\n",
    "> Alternatively, you can combine the training and inference processes into one execution by setting both the 'finetune' and 'inference' parameters to true in the 'disease_prediction.yaml' file and running the command provided in step 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322d32e-372d-46fd-b2a7-56083969a348",
   "metadata": {},
   "source": [
    "<a id=\"expected-output\"></a> \n",
    "## Expected Output\n",
    "A successful execution of inference returns the confusion matrix of the sub-models and ensembled model, as shown in these example results: \n",
    "```\n",
    "------ Confusion Matrix for Vision model ------\n",
    "           Benign  Malignant  Normal  Precision\n",
    "Benign       18.0     11.000   1.000      0.486\n",
    "Malignant     5.0     32.000   0.000      0.615\n",
    "Normal       14.0      9.000  25.000      0.962\n",
    "Recall        0.6      0.865   0.521      0.652\n",
    "\n",
    "------ Confusion Matrix for NLP model ---------\n",
    "           Benign  Malignant  Normal  Precision\n",
    "Benign     25.000      4.000     1.0      0.893\n",
    "Malignant   3.000     34.000     0.0      0.895\n",
    "Normal      0.000      0.000    48.0      0.980\n",
    "Recall      0.833      0.919     1.0      0.930\n",
    "\n",
    "------ Confusion Matrix for Ensemble --------\n",
    "           Benign  Malignant  Normal  Precision\n",
    "Benign     26.000      4.000     0.0      0.897\n",
    "Malignant   3.000     34.000     0.0      0.895\n",
    "Normal      0.000      0.000    48.0      1.000\n",
    "Recall      0.867      0.919     1.0      0.939\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40238669-92d9-49db-9fe8-9045700099fe",
   "metadata": {},
   "source": [
    "<a id=\"result-visualization\"></a> \n",
    "## Result Visualization\n",
    "The following cell displays the study id, images from mammogram and obtained ensemble results from training. Scroll down to see the selected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9319340-c000-46fb-91ca-56f6015e3631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aced918775144ef8f74ad25dce7cec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Select(description='Patient ID:', layout=Layout(grid_area='widget001'), options=('Sel…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'widget_manager' from '/localdisk/aagalleg/dp_demo/disease-prediction-aagalleg/widget_manager.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import widget_manager\n",
    "importlib.reload(widget_manager)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls_env",
   "language": "python",
   "name": "hls_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
